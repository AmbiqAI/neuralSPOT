#!/usr/bin/env python
import os
import sys
from pathlib import Path
from tabulate import tabulate

from neuralspot.tools.utils.tflite_helpers import (
    CreateAddFromSnakeOpName,
    CreateDictFromFlatbuffer,
    OpCodeMapper,
    TensorAnalyze,
)


def analyze_tflite_file(tflite_file, model_name="", verbose=True):  # pylint: disable=invalid-name
    with open(tflite_file, "rb") as file_handle:
        file_data = bytearray(file_handle.read())

    if model_name == "":
        model_name = Path(tflite_file).stem
    
    model_name = model_name.replace("-", "_").replace(" ", "_").replace(".", "_")

    data = CreateDictFromFlatbuffer(file_data)
    count = 0

    # Initialize Return values
    overall_ops_names_list = []
    overall_mac_estimate_list = []
    overall_mac_string_list = []

    # Initialize Return values for output shapes, dilation, and stride
    overall_output_shapes = []
    overall_dilation_h = []
    overall_dilation_w = []
    overall_stride_h = []
    overall_stride_w = []
    overall_mac_filter_list = []
    overall_read_estimate_list = []
    overall_write_estimate_list = []
    output_magnitude_list = []
    input_magnitude_list = []


    opset = []
    code = f"// Autogenerated TFLite Per-Layer Estimated MAC counts, autogenerated by {Path(__file__).stem}\n"
    code += f"uint32_t {model_name}_mac_estimates[] = {{"
    subgraph_length = 0

    # Update builtin code fields.
    for d in data["operator_codes"]:
        d["builtin_code"] = max(d["builtin_code"], d["deprecated_builtin_code"])

    for subgraph_idx, g in enumerate(data["subgraphs"]):
        ops_names_list = []
        mac_estimate_list = []
        mac_estimate_string_list = []
        mac_filter_list = []
        read_estimate_list = []
        write_estimate_list = []
        # output_shapes_list = []
        output_magnitude_list.append([])
        input_magnitude_list.append([])
        overall_mac_string_list.append([])
        overall_output_shapes.append([])
        overall_dilation_h.append([])
        overall_dilation_w.append([])
        overall_stride_h.append([])
        overall_stride_w.append([])
        overall_mac_filter_list.append([])
        overall_read_estimate_list.append([])
        overall_write_estimate_list.append([])

        ta = TensorAnalyze(g)
        op_to_str = OpCodeMapper(data)

        if subgraph_idx > 0:  # only subgraph 0 supported TODO add multi-graph support
            subgraph_length = len(g["operators"])
        else:
            opset.append(op_to_str.code_to_name)  # only subgraph0

        # print(subgraph_idx)
        # print(g["operators"])
        unoptimized_ops = ["LEAKY_RELU", "PAD", "TANH"]

        if g["operators"]:
            for idx, tensor in enumerate(g["operators"]):

                opcodeName = op_to_str(tensor["opcode_index"])

                # If verbose, print warnings for unoptimized ops - only print once per layer type
                if verbose:
                    if opcodeName in unoptimized_ops:
                        print(
                            f"[NS] Static Analysis Warning: {opcodeName} is not in optimized in mainstream TFLM, consider using Ambiq NS-TFLM"
                        )
                        # remove the opcode from the list
                        unoptimized_ops.remove(opcodeName)


                if opcodeName in ["CONV_2D", "DEPTHWISE_CONV_2D", "FULLY_CONNECTED"]:
                    # print("Conv2D, depthwise_conv2d, or fully_connected")
                    # print(opcodeName)
                    # print(tensor)
                    # print(tensor["inputs"])
                    # print(tensor["outputs"])
                    inputs = ta([tensor["inputs"][0]])
                    outputs = ta([tensor["outputs"][0]])
                    if opcodeName == "FULLY_CONNECTED":
                        # Fully connected layers don't have dilation or stride, dummy them out
                        dilation_h = 0
                        dilation_w = 0
                        stride_h = 0
                        stride_w = 0
                    else:
                        dilation_h = tensor["builtin_options"]["dilation_h_factor"]
                        dilation_w = tensor["builtin_options"]["dilation_w_factor"]
                        stride_h = tensor["builtin_options"]["stride_h"]
                        stride_w = tensor["builtin_options"]["stride_w"]
                else:
                    # print all existing data (inputs, outputs, opcodeName) for debugging
                    if tensor:
                        # print("Not conv2d, depthwise_conv2d, or fully_connected")
                        # print(opcodeName)
                        # print ("Tensor")
                        # print (tensor)
                        # print (tensor["inputs"])
                        # print (tensor["outputs"])
                        if tensor["inputs"]:
                            inputs = ta([tensor["inputs"][0]])
                            if not inputs["shape"]:
                                inputs["shape"] = [0, 0, 0, 0]
                        else:
                            inputs = {"shape": [0, 0, 0, 0]}
                        # inputs = ta([tensor["inputs"][0]])
                        if tensor["outputs"]:
                            outputs = ta([tensor["outputs"][0]])
                            # Some output shapes are scalar, make it an empty list
                            if not outputs["shape"]:
                                outputs["shape"] = [0, 0, 0, 0]
                        else:
                            outputs = {"shape": [0, 0, 0, 0]}


                        # outputs = ta([tensor["outputs"][0]])
                        dilation_h = 0
                        dilation_w = 0
                        stride_h = 0
                        stride_w = 0
                        # print(inputs)
                        # print(outputs)
                    else:
                        print("WARNING: No tensor data for " + opcodeName)
                # print(tensor)
                # print(opcodeName)
                # print(f"output shape: {outputs['shape']}")
                # output_shapes_list = outputs["shape"]
                overall_output_shapes[subgraph_idx].append(f'{outputs["shape"]}'.replace(", ","*").replace("[", "").replace("]", ""))
                overall_dilation_h[subgraph_idx].append(dilation_h)
                overall_dilation_w[subgraph_idx].append(dilation_w)
                overall_stride_h[subgraph_idx].append(stride_h)
                overall_stride_w[subgraph_idx].append(stride_w)

                # Calculate the magnitude of the output tensor (multiple the dimensions)
                output_magnitude = 1
                for dim in outputs["shape"]:
                    output_magnitude *= dim
                # print(f"output magnitude: {output_magnitude}")
                output_magnitude_list[subgraph_idx].append(output_magnitude)

                input_magnitude = 1
                for dim in inputs["shape"]:
                    input_magnitude *= dim
                # print(f"input magnitude: {input_magnitude}")
                input_magnitude_list[subgraph_idx].append(input_magnitude)

                if opcodeName == "CONV_2D":
                    # Conv2D
                    """
                    output_channels = filter->dims->data[0];
                    filter_width = filter->dims->data[1];
                    filter_height = filter->dims->data[2];
                    input_channels = filter->dims->data[3];
                    output_width = output->dims->data[1];
                    output_height = output->dims->data[2];
                    """
                    # filter_width * filter_height * output_width * output_height * input_channels * output_channels
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                        * filter["shape"][0]
                        * inputs["shape"][3]
                    )
                    mac_string = f"{filter['shape'][1]}*{filter['shape'][2]}*{outputs['shape'][1]}*{outputs['shape'][2]}*{filter['shape'][0]}*{inputs['shape'][3]}"

                    # Calculate estimated memory reads for this operation
                    memory_reads = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * inputs["shape"][3]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                    )

                    # Calculate estimated memory writes for this operation
                    memory_writes = outputs["shape"][1] * outputs["shape"][2] * outputs["shape"][3]

                elif opcodeName == "DEPTHWISE_CONV_2D":
                    """
                    filter_width = filter->dims->data[1];
                    filter_height = filter->dims->data[2];
                    channels = filter->dims->data[3];
                    output_width = output->dims->data[1];
                    output_height = output->dims->data[2];
                    """
                    # filter_width * filter_height * output_width * output_height * channels
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                        * filter["shape"][3]
                    )
                    mac_string = f"{filter['shape'][1]}*{filter['shape'][2]}*{outputs['shape'][1]}*{outputs['shape'][2]}*{filter['shape'][3]}"

                    # Calculate estimated memory reads for this operation
                    memory_reads = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * inputs["shape"][3]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                    )

                    # Calculate estimated memory writes for this operation
                    memory_writes = outputs["shape"][1] * outputs["shape"][2] * outputs["shape"][3]
                elif opcodeName == "FULLY_CONNECTED":
                    """
                    num_batches = output_shape.Dims(0);
                    output_depth = output_shape.Dims(1);
                    accum_depth = filter_shape.Dims(-1);
                    macs = accum_depth * output_depth * batch_size
                    """
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][-1] * outputs["shape"][0] * outputs["shape"][1]
                    )
                    mac_string = f"{filter['shape'][-1]}*{outputs['shape'][0]}*{outputs['shape'][1]}"
                    # Calculate estimated memory reads for this operation
                    memory_reads = filter["shape"][-1] * outputs["shape"][0] * outputs["shape"][1]
                    # Calculate estimated memory writes for this operation
                    memory_writes = outputs["shape"][0] * outputs["shape"][1]
                else:
                    macs = 0

                    # Assume that for all other operations, the reads correspond to the input tensor magnitudes
                    # and writes correspond to the output tensor magnitudes
                    # input tetor magnitudes are the product of all dimensions of the input tensors
                    memory_reads = input_magnitude
                    memory_writes = output_magnitude

                    # Calculate estimated memory reads for non-convolution operations
                    # if opcodeName == "ADD" or opcodeName == "MUL" or opcodeName == "SUB" or opcodeName == "DIV" or opcodeName == "LOGISTIC" or opcodeName == "SOFTMAX" or opcodeName == "AVERAGE_POOL_2D" or opcodeName == "MAX_POOL_2D":
                    #     memory_reads = inputs["shape"][0] * inputs["shape"][1] * inputs["shape"][2] * inputs["shape"][3]
                    #     memory_writes = outputs["shape"][0] * outputs["shape"][1] * outputs["shape"][2] * outputs["shape"][3]
                    # elif opcodeName == "RELU":
                    #     memory_reads = inputs["shape"][0] * inputs["shape"][1] * inputs["shape"][2] * inputs["shape"][3]
                    #     memory_writes = outputs["shape"][0] * outputs["shape"][1] * outputs["shape"][2] * outputs["shape"][3]
                    # elif opcodeName == "PAD":

                    # else:

                    mac_string = "0"
                    filter = {"shape": [0, 0, 0, 0]}
                # print (f"MACs: {macs}")
                # print (f"MAC String: {mac_string}")

                # for convolution ops, check the filter shape for unoptimized paths
                if verbose and opcodeName in ["CONV_2D", "DEPTHWISE_CONV_2D"]:
                    if filter["shape"][2] == 1 and filter["shape"][1] != 1:
                        print(
                            f"[NS] Static Analysis Warning: Op #{count}: 1D {opcodeName} BHWC W is 1 which is not optimally implemented in CMSIS-NN, consider swapping to B1WC - shape {filter['shape']}"
                        )
                ops_names_list.append(opcodeName)
                mac_estimate_list.append(macs)
                read_estimate_list.append(memory_reads)
                write_estimate_list.append(memory_writes)
                mac_estimate_string_list.append(mac_string)
                # print("mac string: ", mac_string)
                # print("mac estimate list: ", mac_estimate_string_list)
                mac_filter_list.append(f'{filter["shape"]}'.replace("[", "").replace("]", "").replace(", ","*"))

                if subgraph_idx == 0:
                    code = code + repr(macs) + ", "
                    count = count + 1
                    # print (count)
                    # print(code)
            
            overall_ops_names_list.append(ops_names_list)
            overall_mac_estimate_list.append(mac_estimate_list)
            overall_mac_string_list[subgraph_idx] = mac_estimate_string_list
            overall_mac_filter_list[subgraph_idx] = mac_filter_list
            overall_read_estimate_list[subgraph_idx] = read_estimate_list
            overall_write_estimate_list[subgraph_idx] = write_estimate_list
            # overall_mac_filter_list = f"{mac_filter_list}".replace("[", '"').replace("]", '"')
            # print (overall_mac_filter_list)
            # print(overall_mac_string_list)
            # overall_output_shapes.append(output_shapes_list)

        if subgraph_idx == 0:
            code = code + "};\n\n"
            code = (
                code
                + "const int "
                + model_name
                + "_number_of_estimates = "
                + repr(count)
                + ";\n"
            )

    # Add the output shapes to the code
    # print("length of output shapes: ", len(overall_output_shapes))

    # Start building the code starting from highest subgraph, all lengths are the same
    code_output_shapes = ""
    code_output_magnitude = ""
    code_mac_strings = ""
    code_mac_filter = ""
    code_stride_h = ""
    code_stride_w = ""
    code_dilation_h = ""
    code_dilation_w = ""
    code_read_estimate = ""
    code_write_estimate = ""

    for g in range(len(overall_output_shapes)-1, -1, -1):
        # print("g: ", g)
        code_output_shapes = code_output_shapes + repr(overall_output_shapes[g]) + ", " 
        code_output_magnitude = code_output_magnitude + repr(output_magnitude_list[g]) + ", "
        code_mac_strings = code_mac_strings + repr(overall_mac_string_list[g]) + ", "
        code_mac_filter = code_mac_filter + repr(overall_mac_filter_list[g]) + ", "
        code_stride_h = code_stride_h + repr(overall_stride_h[g]) + ", "
        code_stride_w = code_stride_w + repr(overall_stride_w[g]) + ", "
        code_dilation_h = code_dilation_h + repr(overall_dilation_h[g]) + ", "
        code_dilation_w = code_dilation_w + repr(overall_dilation_w[g]) + ", "
        code_read_estimate = code_read_estimate + repr(overall_read_estimate_list[g]) + ", "
        code_write_estimate = code_write_estimate + repr(overall_write_estimate_list[g]) + ", "
    
    # now make is code friendly
    code_output_shapes = code_output_shapes.replace("[", "").replace("]", "").replace("'", '"')
    code_output_magnitude = code_output_magnitude.replace("[", "").replace("]", "")
    code_mac_strings = code_mac_strings.replace("[", "").replace("]", "").replace("'", '"')
    code_mac_filter = code_mac_filter.replace("[", "").replace("]", "").replace("'", '"')
    code_stride_h = code_stride_h.replace("[", "").replace("]", "")
    code_stride_w = code_stride_w.replace("[", "").replace("]", "")
    code_dilation_h = code_dilation_h.replace("[", "").replace("]", "")
    code_dilation_w = code_dilation_w.replace("[", "").replace("]", "")
    code_read_estimate = code_read_estimate.replace("[", "").replace("]", "")
    code_write_estimate = code_write_estimate.replace("[", "").replace("]", "")

    code_output_shapes = f"const char* {model_name}_output_shapes[] = {{" + code_output_shapes + "};\n"
    code_output_magnitude = f"const uint32_t {model_name}_output_magnitudes[] = {{" + code_output_magnitude + "};\n"
    code_mac_strings = f"const char* {model_name}_mac_strings[] = {{" + code_mac_strings + "};\n"
    code_mac_filter = f"const char* {model_name}_mac_filter_shapes[] = {{" + code_mac_filter + "};\n"
    code_stride_h = f"const uint32_t {model_name}_stride_h[] = {{" + code_stride_h + "};\n"
    code_stride_w = f"const uint32_t {model_name}_stride_w[] = {{" + code_stride_w + "};\n"
    code_dilation_h = f"const uint32_t {model_name}_dilation_h[] = {{" + code_dilation_h + "};\n"
    code_dilation_w = f"const uint32_t {model_name}_dilation_w[] = {{" + code_dilation_w + "};\n"
    code_read_estimate = f"const uint32_t {model_name}_read_estimate[] = {{" + code_read_estimate + "};\n"
    code_write_estimate = f"const uint32_t {model_name}_write_estimate[] = {{" + code_write_estimate + "};\n"


        # print(code_mac_strings)
        # print(code_output_shapes)
        # print(code_output_magnitude)
        # print(code_stride_h)
        # print(code_stride_w)
        # print(code_dilation_h)
        # print(code_dilation_w)
        # print(code_mac_filter)

        # The rest of the toolchain is ussing mac estimate list directly, and not the code
        # so we will repurpose the code retval to return the other lists as a code blob
    code = code_mac_strings + code_output_shapes + code_output_magnitude + code_stride_h + code_stride_w + code_dilation_h + code_dilation_w + code_mac_filter + code_write_estimate + code_read_estimate


    return (
        code,
        overall_ops_names_list,
        overall_mac_estimate_list,
        overall_mac_string_list,
        opset,
        len(data["subgraphs"]),
        overall_output_shapes,
        overall_dilation_h,
        overall_dilation_w,
        overall_stride_h,
        overall_stride_w,
        overall_mac_filter_list,
        overall_read_estimate_list,
        overall_write_estimate_list,
        output_magnitude_list,
        input_magnitude_list,
    )


def main(argv):
    try:
        tflite_input = argv[1]
    except IndexError:
        print("Usage: %s <input tflite>" % (argv[0]))
    else:
        code, ops, macs, mac_strings, opset, slen, overall_output_shapes,\
        overall_dilation_h,\
        overall_dilation_w,\
        overall_stride_h,\
        overall_stride_w,\
        overall_mac_filter_list,\
        overall_read_estimate_list,\
        overall_write_estimate_list, \
        output_magnitude_list, \
        input_magnitude_list = analyze_tflite_file(tflite_input, verbose=True)

        # print(opset[0])
        # print("mac strings: ", mac_strings)
        # print("macs: ", macs)
        # print("overall mac filter list: ", overall_mac_filter_list)
        # print(code)

        for i, opname in opset[0].items():
            CreateAddFromSnakeOpName(opname)

        # Print all that data in a nice table format
        # First, create the header
        headers = ["Subgraph","Index", "Ops", "Estimated_MACs", "MAC_Eq", "Output_Shape", "Dilation_H", "Dilation_W", "Stride_H", "Stride_W", "Filter_Shape", "Estimated_Reads", "Estimated_Writes", "Input_Magnitude", "Output_Magnitude"]
        table = [headers]
        for subgraph in range(slen):
            for op in range(len(ops[subgraph])):
                print(f"Subgraph {subgraph}, Op {op}")
                row = [subgraph, op, ops[subgraph][op], macs[subgraph][op], mac_strings[subgraph][op], overall_output_shapes[subgraph][op], overall_dilation_h[subgraph][op], overall_dilation_w[subgraph][op], overall_stride_h[subgraph][op], overall_stride_w[subgraph][op], overall_mac_filter_list[subgraph][op], overall_read_estimate_list[subgraph][op], overall_write_estimate_list[subgraph][op], input_magnitude_list[subgraph][op], output_magnitude_list[subgraph][op]]
                table.append(row)
        
        print(tabulate(table, headers="firstrow", tablefmt="fancy_grid"))

        # Write the result to a CSV with same name as TFLite file, but in local directory
        csv_filename = Path(tflite_input).stem + ".csv"
        with open(csv_filename, "w") as f:
            for row in table:
                f.write(",".join([str(x) for x in row]) + "\n")

        # Write as Excel file
        excel_filename = Path(tflite_input).stem + ".xlsx"
        import pandas as pd
        df = pd.DataFrame(table[1:], columns=table[0])
        df.to_excel(excel_filename, index=False)
        

        # print(code)
        # print(ops)
        # print(str(macs).replace("[", "").replace("]", ""))
        # print(macs)
        # print(slen)


if __name__ == "__main__":
    main(sys.argv)
