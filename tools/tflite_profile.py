#!/usr/bin/env python
import json
import os
import re
import sys
from pathlib import Path

import numpy as np
import schema_py_generated as schema_fb


def TensorTypeToName(tensor_type):
    """Converts a numerical enum to a readable tensor type."""
    for name, value in schema_fb.TensorType.__dict__.items():
        if value == tensor_type:
            return name
    return None


def BuiltinCodeToName(code):
    """Converts a builtin op code enum to a readable name."""
    for name, value in schema_fb.BuiltinOperator.__dict__.items():
        if value == code:
            return name
    return None


def NameListToString(name_list):
    """Converts a list of integers to the equivalent ASCII string."""
    if isinstance(name_list, str):
        return name_list
    else:
        result = ""
        if name_list is not None:
            for val in name_list:
                result = result + chr(int(val))
        return result


class OpCodeMapper:
    """Maps an opcode index to an op name."""

    def __init__(self, data):
        self.code_to_name = {}
        for idx, d in enumerate(data["operator_codes"]):
            self.code_to_name[idx] = BuiltinCodeToName(d["builtin_code"])
            if self.code_to_name[idx] == "CUSTOM":
                self.code_to_name[idx] = NameListToString(d["custom_code"])

    def __call__(self, x):
        if x not in self.code_to_name:
            s = "<UNKNOWN>"
        else:
            s = self.code_to_name[x]
        return "%s (%d)" % (s, x)


class DataSizeMapper:
    """For buffers, report the number of bytes."""

    def __call__(self, x):
        if x is not None:
            return "%d bytes" % len(x)
        else:
            return "--"


def FlatbufferToDict(fb, preserve_as_numpy):
    """Converts a hierarchy of FB objects into a nested dict.

    We avoid transforming big parts of the flat buffer into python arrays. This
    speeds conversion from ten minutes to a few seconds on big graphs.

    Args:
      fb: a flat buffer structure. (i.e. ModelT)
      preserve_as_numpy: true if all downstream np.arrays should be preserved.
        false if all downstream np.array should become python arrays
    Returns:
      A dictionary representing the flatbuffer rather than a flatbuffer object.
    """
    if isinstance(fb, int) or isinstance(fb, float) or isinstance(fb, str):
        return fb
    elif hasattr(fb, "__dict__"):
        result = {}
        for attribute_name in dir(fb):
            attribute = fb.__getattribute__(attribute_name)
            if not callable(attribute) and attribute_name[0] != "_":
                snake_name = CamelCaseToSnakeCase(attribute_name)
                preserve = True if attribute_name == "buffers" else preserve_as_numpy
                result[snake_name] = FlatbufferToDict(attribute, preserve)
        return result
    elif isinstance(fb, np.ndarray):
        return fb if preserve_as_numpy else fb.tolist()
    elif hasattr(fb, "__len__"):
        return [FlatbufferToDict(entry, preserve_as_numpy) for entry in fb]
    else:
        return fb


def CamelCaseToSnakeCase(camel_case_input):
    """Converts an identifier in CamelCase to snake_case."""
    s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", camel_case_input)
    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1).lower()


def CreateDictFromFlatbuffer(buffer_data):
    model_obj = schema_fb.Model.GetRootAsModel(buffer_data, 0)
    model = schema_fb.ModelT.InitFromObj(model_obj)
    return FlatbufferToDict(model, preserve_as_numpy=False)


class TensorAnalyze:
    """Maps a list of tensor indices to a tooltip hoverable indicator of more."""

    def __init__(self, subgraph_data):
        self.data = subgraph_data

    def __call__(self, x):
        r = {}
        if x is None:
            return r

        for i in x:
            tensor = self.data["tensors"][i]

            r["name"] = NameListToString(tensor["name"]) + ", "
            r["type"] = TensorTypeToName(tensor["type"]) + ", "
            r["shape"] = tensor["shape"] if "shape" in tensor else []

        return r


def print_code(tflite_input, input_is_filepath=True):  # pylint: disable=invalid-name
    with open(tflite_input, "rb") as file_handle:
        file_data = bytearray(file_handle.read())

    model_name = Path(tflite_input).stem
    data = CreateDictFromFlatbuffer(file_data)
    count = 0
    code = """
// TFLite Per-Layer Estimated MAC counts, generated by ns_tflite_profile.py

"""
    code += "uint32_t " + model_name + "_mac_estimates[] = {" ""
    # Update builtin code fields.
    for d in data["operator_codes"]:
        d["builtin_code"] = max(d["builtin_code"], d["deprecated_builtin_code"])

    for subgraph_idx, g in enumerate(data["subgraphs"]):
        ta = TensorAnalyze(g)
        op_to_str = OpCodeMapper(data)

        if g["operators"]:
            for idx, tensor in enumerate(g["operators"]):
                inputs = ta([tensor["inputs"][0]])
                outputs = ta([tensor["outputs"][0]])
                opcode = tensor["opcode_index"]
                if opcode == 0:
                    # Conv2D
                    """
                    output_channels = filter->dims->data[0];
                    filter_width = filter->dims->data[1];
                    filter_height = filter->dims->data[2];
                    input_channels = filter->dims->data[3];
                    output_width = output->dims->data[1];
                    output_height = output->dims->data[2];
                    """
                    # filter_width * filter_height * output_width * output_height * input_channels * output_channels
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                        * outputs["shape"][0]
                        * inputs["shape"][3]
                    )
                elif opcode == 1:
                    """
                    filter_width = filter->dims->data[1];
                    filter_height = filter->dims->data[2];
                    channels = filter->dims->data[3];
                    output_width = output->dims->data[1];
                    output_height = output->dims->data[2];
                    """
                    # filter_width * filter_height * output_width * output_height * channels
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][1]
                        * filter["shape"][2]
                        * outputs["shape"][1]
                        * outputs["shape"][2]
                        * filter["shape"][3]
                    )
                elif opcode == 4:
                    """
                    num_batches = output_shape.Dims(0);
                    output_depth = output_shape.Dims(1);
                    accum_depth = filter_shape.Dims(-1);
                    macs = accum_depth * output_depth * batch_size
                    """
                    filter = ta([tensor["inputs"][1]])
                    macs = (
                        filter["shape"][-1] * outputs["shape"][0] * outputs["shape"][1]
                    )
                else:
                    macs = 0
                code = code + repr(macs) + ", "
                count = count + 1

            code = code + "};\n\n"
            code = (
                code
                + "const int "
                + model_name
                + "_number_of_estimates = "
                + repr(count)
                + ";"
            )
    return code


def main(argv):
    try:
        tflite_input = argv[1]
    except IndexError:
        print("Usage: %s <input tflite> <output html>" % (argv[0]))
    else:
        code = print_code(tflite_input)
        print(code)


if __name__ == "__main__":
    main(sys.argv)
